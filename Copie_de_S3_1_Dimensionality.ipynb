{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0-WlA6efBRki"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanguy-linard/2024_MLEES/blob/main/Copie_de_S3_1_Dimensionality.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dimensionality Reduction"
      ],
      "metadata": {
        "id": "fab2zKXwAinB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src='https://unils-my.sharepoint.com/:i:/g/personal/tom_beucler_unil_ch/EX7KlNGWYypLnH_53OnJR6oBjfgb_gCZ4gmnOeR68a6zMA?download=1'>\n",
        "<center> Caption: <i>Denise diagnoses an overheated CPU at our data center in The Dalles, Oregon. <br> For more than a decade, we have built some of the world's most efficient servers.</i> <br> Photo from the <a href='https://www.google.com/about/datacenters/gallery/'>Google Data Center gallery</a> </center>"
      ],
      "metadata": {
        "id": "y7Q5WigQxsVd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Our world is increasingly filled with data from all sorts of sources, including environmental data. Can we reduce the data to a reduced, meaningful space to save on computation time and increase explainability?*"
      ],
      "metadata": {
        "id": "XGGHmOj1ygXe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will be used in the lab session for week 4 of the course, covers Chapters 8 of Géron, and builds on the [notebooks made available on _Github_](https://github.com/ageron/handson-ml2).\n",
        "\n",
        "Need a reminder of last week's labs? Click [_here_](https://colab.research.google.com/github/tbeucler/2022_ML_Earth_Env_Sci/blob/main/Lab_Notebooks/Week_3_Decision_Trees_Random_Forests_SVMs.ipynb) to go to notebook for week 3 of the course."
      ],
      "metadata": {
        "id": "AlTDG-57-aAI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notebook Setup**\n",
        "\n",
        "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
      ],
      "metadata": {
        "id": "0-WlA6efBRki"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zw6fcA3O-Uls"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "rnd_seed = 42\n",
        "rnd_gen = np.random.default_rng(rnd_seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"dim_reduction\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dimensionality Reduction using PCA\n",
        "\n",
        "This week we'll be looking at how to reduce the dimensionality of a large dataset in order to improve our classifying algorithm's performance! With that in mind, let's being the exercise by loading the MNIST dataset.\n",
        "\n",
        "## Q1) Load the input features and truth variable into X and y, then split the data into a training and test dataset using scikit's train_test_split method. Use *test_size=0.15*, and remember to set the random state to *rnd_seed!*\n",
        "\n",
        "*Hint 1: The `'data'` and `'target'` keys for mnist will return X and y.*\n",
        "\n",
        "*Hint 2: [Here's the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) for train/test split.*"
      ],
      "metadata": {
        "id": "H3QU33M3D--N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the mnist dataset\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)"
      ],
      "metadata": {
        "id": "H9slNfR3D-kg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in the mnist digit images and corresponding numbers\n",
        "# ---------------------------------------------------------------------------\n",
        "# The procedure here is similar to the notebooks we did last week. Use Hint 1 to store the input and target data.\n",
        "X = mnist['data']\n",
        "y = mnist['target']"
      ],
      "metadata": {
        "id": "zNcNkJ3u92cW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TextIO\n",
        "# Import train_test_split() to create your training and test sets\n",
        "# ---------------------------------------------------------------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Now separate your X and y into training and test sets (use train_test_split)\n",
        "# ---------------------------------------------------------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=rnd_seed) # (data,target,test_size,random_state)"
      ],
      "metadata": {
        "id": "yOmYNwuT920P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now once again have a training and testing dataset with which to work with. Let's try training a random forest tree classifier on it. You've had experience with them before, so let's have you import the `RandomForestClassifier` from sklearn and instantiate it.\n",
        "\n",
        "## Q2) Import the `RandomForestClassifier` model from sklearn. Then, instantiate it with 100 estimators and set the random state to *rnd_seed!*\n",
        "\n",
        "*Hint 1: [Here's the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) for `RandomForestClassifier`*\n",
        "\n",
        "*Hint 2: [Here's the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) for train/test split.*\n",
        "\n",
        "*Hint 3: If you're still confused about **instantiation**, there's a [blurb on wikipedia](https://en.wikipedia.org/wiki/Instance_(computer_science)) describing it in the context of computer science.*"
      ],
      "metadata": {
        "id": "EhBQOdVxfr2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import RandomForestClassifier here.\n",
        "# ---------------------------------------------------------------------------\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "ZZaWwNGUg9Qb"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we initiate a RF classifier objects with custom settings: 100 estimators, random_state=rnd_seed\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "rnd_clf = RandomForestClassifier(n_estimators=100, #Number of estimators\n",
        "                random_state=rnd_seed) #Random State"
      ],
      "metadata": {
        "id": "qJc0deCO-Ibt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're now going to measure how quickly the algorithm is fitted to the mnist dataset! To do this, we'll have to import the `time` library. With it, we'll be able to get a timestamp immediately before and after we fit the algorithm, and we'll get the time by calculating the difference.\n",
        "\n",
        "## Q3) Import the time library and calculate how long it takes to fit the `RandomForestClassifier` model.\n",
        "\n",
        "*Hint 1: [Here's the documentation](https://docs.python.org/3/library/time.html#time.time) to the function used for getting timestamps*\n",
        "\n",
        "*Hint 2: [Here's the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.fit) for the fitting method used in `RandomForestClassifier`.*"
      ],
      "metadata": {
        "id": "gi1HTS-KjUJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "EZaQPn2XkV06"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a function in time (check documentation) to load **current** time before training the RF classifier\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "t0 = time.time()\n",
        "\n",
        "# Train the RF classifier\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "\n",
        "# Use the same function for t0 to load **current** time **after** training the RF classifier\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "t1 = time.time()"
      ],
      "metadata": {
        "id": "B4jPNCXl-OIM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this as is, how many seconds did it take to train the classifier?\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "train_t_rf = t1-t0\n",
        "\n",
        "print(f\"Training took {train_t_rf:.2f}s\")"
      ],
      "metadata": {
        "id": "LFuLLVWj-PXZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1a29ec4-d3f6-4c86-df98-62e8ddeb5c8c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training took 51.59s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We care about more than just how long we took to trian the model, however! Let's get an accuracy score for our model.\n",
        "\n",
        "## Q4) Get an accuracy score for the predictions from the RandomForestClassifier\n",
        "\n",
        "*Hint 1: [Here is the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) for the `accuracy_score` metric in sklearn.*\n",
        "\n",
        "*Hint 2: [Here is the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier.predict) for the predict method in `RandomForestClassifier`*"
      ],
      "metadata": {
        "id": "X0-hEhlOnLqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the accuracy score metric in scikit-learn (check Hint 1 for ideas on how to import metrics)\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "lscBW_sFnLVS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now try to use the trained classifier to generate predictions for the unseen test set (X_test)\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "y_pred = rnd_clf.predict(X_test)"
      ],
      "metadata": {
        "id": "x-93C_-n-cle"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the accuracy_score() metric on y_test and y_pred to evaluate the accuracy of our model\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "rf_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Run this as is. We got an accuracy of 96.7%. Did you get similar scores?\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "print(f\"RF Model Accuracy: {rf_accuracy:.2%}\")"
      ],
      "metadata": {
        "id": "n09PnHuy-cTf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42bb82b-2a01-43ed-c2a7-df6dc32cfdf3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF Model Accuracy: 96.71%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try doing the same with with a logistic regression algorithm to see how it compares.\n",
        "\n",
        "## Q5) Repeat Q2-4 with a logistic regression algorithm using sklearn's `LogisticRegression` class. Hyperparameters: `multi_class='multinomial'` and `solver='lbfgs'`\n",
        "\n",
        "*Hint 1: [Here is the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) for the `LogisticRegression` class."
      ],
      "metadata": {
        "id": "XEZX7xBAHJj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import LogisticRegression class here.\n",
        "# ---------------------------------------------------------------------------\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "kwX8ZwzQI6p6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initiate a LogisticRegression object with custom hyperparameters\n",
        "# ---------------------------------------------------------------------------\n",
        "log_clf = LogisticRegression(multi_class=\"multinomial\", #Multiclass\n",
        "                solver=\"lbfgs\",  #Solver\n",
        "                random_state=42) #Random State"
      ],
      "metadata": {
        "id": "CvUwrxtS-mTf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Timestamp for **current** time before training the LogisticRegression classifier\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "t0 = time.time()\n",
        "\n",
        "# Training the LogisticRegression classifier\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "log_clf.fit(X_train, y_train)\n",
        "\n",
        "# Timestamp for **current** time after training the LogisticRegression classifier\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "t1 = time.time()\n",
        "\n",
        "# Run this as is, how many seconds did it take to train the classifier?\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "train_t_log = t1-t0\n",
        "print(f\"Training took {train_t_log:.2f}s\")"
      ],
      "metadata": {
        "id": "F6Dr9j1T-mgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14d742b4-65e3-412f-9365-6d8f909ca57b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training took 52.72s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now try to use the trained classifier to generate predictions for the unseen test set (X_test)\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "y_pred = log_clf.predict(X_test)\n",
        "\n",
        "# Run this as is. We got an accuracy of 92.1%. Did you get similar scores?\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "log_accuracy = accuracy_score(y_test, y_pred)  # Feed in the truth and predictions\n",
        "\n",
        "print(f\"Log Model Accuracy: {log_accuracy:.2%}\")"
      ],
      "metadata": {
        "id": "Armw_a0V-mAs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97d3f25-80cf-4eec-80ee-0412ef452204"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Model Accuracy: 92.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Up to now, everything that we've done are things we've done in previous labs - but now we'll get to try out some algorithms useful for reducing dimensionality! Let's use principal component analysis. Here, we'll reduce the space using enough axes to explain over 95% of the variability in the data...\n",
        "\n",
        "## Q6) Import scikit's implementation of `PCA` and fit it to the training dataset so that 95% of the variability is explained.\n",
        "\n",
        "*Hint 1: [Here is the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) for scikit's `PCA` class.*\n",
        "\n",
        "*Hint 2: [Here is the documentation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA.fit_transform) for scikit's `.fit_transform()` method.*"
      ],
      "metadata": {
        "id": "b_5XiaQfJ5NV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we will experiment a bit with reducing the dimensionality of the mnist data.\n",
        "# First, import the PCA class from scikit-learn\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "from sklearn.decomposition import PCA # Importing PCA"
      ],
      "metadata": {
        "id": "rrP5043rJc-1"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will now initiate the PCA algorithm, with a custom hyperparameter to only keep only a certain amount of PC components\n",
        "# In the documentation, search for the keywords \"numbers ... to keep\"\n",
        "# ---------------------------------------------------------------------------------------------------------------------------\n",
        "pca = PCA(n_components=0.95) # Set number of components to explain 95% of variability"
      ],
      "metadata": {
        "id": "UZAeoAlI_Ok9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the PCA model and use it to transform our training data (reducing data dimentionality) [fit_transform]\n",
        "# ---------------------------------------------------------------------------------------------------------------------------\n",
        "X_train_reduced = pca.fit_transform(X_train) # Fit-transform the training data"
      ],
      "metadata": {
        "id": "b3FHiYMA_OwR"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform our test data (reducing data dimentionality) with the pca algorithm (do not fit the model again!)\n",
        "# ---------------------------------------------------------------------------------------------------------------------------\n",
        "X_test_reduced = pca.transform(X_test)"
      ],
      "metadata": {
        "id": "zydXZOAV_T1U"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q7) Repeat Q3 & Q4 using the *reduced* `X_train` dataset instead of `X_train`."
      ],
      "metadata": {
        "id": "mKXeXWn4M8K1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load current time step, train RF classifier with X_train_reduced, load time step after training\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "t0 = time.time() # Load the timestamp before running\n",
        "rnd_clf.fit(X_train_reduced, y_train) # Fit the model with the reduced training data\n",
        "t1 = time.time()  # Load the timestamp after running\n",
        "\n",
        "# How many seconds did it take to train the model?\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "train_t_rf = t1-t0\n",
        "print(f\"Training took {train_t_rf:.2f}s\")"
      ],
      "metadata": {
        "id": "m1oZFFfljH0N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16e41ae5-2b0a-4a21-8626-841d6f9c3925"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training took 188.06s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use trained classifier to generate predictions from the **reduced** test set (X_test_reduced)\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "y_pred = rnd_clf.predict(X_test_reduced)\n",
        "\n",
        "# Use accuracy_score to compare truth and prediction. We got 94.7% accuracy.\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "red_rf_accuracy = accuracy_score(y_test, y_pred)  # Feed in the truth and predictions\n",
        "print(f\"RF Model Accuracy on reduced dataset: {red_rf_accuracy:.2%}\")"
      ],
      "metadata": {
        "id": "jNisAXlgnUMe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a9a0853-4ac4-4941-eb9b-d96642b68cdc"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RF Model Accuracy on reduced dataset: 94.63%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q8) Repeat Q5 using the *reduced* X_train dataset instead of X_train."
      ],
      "metadata": {
        "id": "46j-guE8NStk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load current time step, train LogisticRegression with X_train_reduced, load time step after training\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "t0 = time.time() # Timestamp before training\n",
        "log_clf.fit(X_train_reduced, y_train) # Fit the model with the reduced training data\n",
        "t1 = time.time() # Timestamp after training\n",
        "\n",
        "# How many seconds did it take to train the model?\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "train_t_log = t1-t0\n",
        "print(f\"Training took {train_t_log:.2f}s\")"
      ],
      "metadata": {
        "id": "JerFiDoKMpAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "416c457e-2c36-4695-c512-2b3eade9749d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training took 7.31s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use trained classifier to generate predictions from the **reduced** test set (X_test_reduced)\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "y_pred = log_clf.predict(X_test_reduced)   # Get a set of predictions from the test set\n",
        "\n",
        "\n",
        "# Use accuracy_score to compare truth and prediction. We got 91.38% accuracy.\n",
        "# ------------------------------------------------------------------------------------------------------\n",
        "log_accuracy = accuracy_score(y_test, y_pred)  # Feed in the truth and predictions\n",
        "print(f\"Log Model Accuracy on reduced training data: {log_accuracy:.2%}\")"
      ],
      "metadata": {
        "id": "R3Pc9LRK_f4I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0d516ac-dd6e-453f-9c30-0e7c68f0c506"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Log Model Accuracy on reduced training data: 91.38%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can now compare how well the random forest classifier and logistic regression classifier performed on both the full dataset and the reduced dataset. What were you able to observe?"
      ],
      "metadata": {
        "id": "_P_-tnZstz99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write your comments on the performance of the algorithms in this box, if you'd like 😀\n",
        "(Double click to activate editing mode)"
      ],
      "metadata": {
        "id": "6AFlS89UuZTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_times = [train_t_rf, train_t_log]\n",
        "accuracy_scores = [rf_accuracy, log_accuracy]\n",
        "plt.scatter(train_times, accuracy_scores)\n",
        "plt.xlabel('Time[s]')\n",
        "plt.ylabel('accuracy_score[%]')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "Fn7NaTWVmjcf",
        "outputId": "335e9f6e-1baf-4527-a83c-41a523adcf0e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'accuracy_score[%]')"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ynNAgnNynAmU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}